{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 8\n",
    "\n",
    "## MGT 575 Spring 2021\n",
    "##  Social Media Analytics\n",
    "\n",
    "#### Handout date: April 7th, 2021\n",
    "#### Due date: April 14th, 2021 \n",
    "\n",
    "You can load this notebook from Colab here: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zlisto/natural_language_generation/blob/main/HW8.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1. (56 points) Compare Decoding Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. (4 points) Load GPT-2 Model\n",
    "\n",
    "Load the GPT-2 transformer using the `pipeline` function and configure it for `\"text-generation\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. (8 points) Greedy Search\n",
    "\n",
    "Set `input_text = \"Hi my name is\"` and use greedy search to generate a text of maximum length 50 using your GPT-2 `generator`.  Print out your results using the `display_text` function from Lecture 19 (copying and pasting works here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. (8 points) Beam Search\n",
    "\n",
    "Set `input_text = \"Hi my name is\"` and use beam search with 10 beams to generate a text of maximum length 50 using your GPT-2 `generator`.  Print out your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (8 points) Beam versus Greedy Search\n",
    "\n",
    "Repeat Problem 1.3, but now use only 1 beam.  Print our your results.  You might notice this looks like greedy search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. (10 points) Sampling with Temperature\n",
    "\n",
    "Set `input_text = \"Hi my name is\"` and use sampling with temperature to generate 5 texts of maximum length 50 using your GPT-2 `generator`.  Set the temperature to 0.5, 1, 2, and 3 (a `for` loop might be useful here).    Print out your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. (4 points) Temperature Effect\n",
    "\n",
    "Describe the qualitative difference in the generated text as the temperature increases.  Discuss both the variety of the text and the coherence of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. (10 points) Top-P Sampling\n",
    "\n",
    "Set `input_text = \"Hi my name is\"` and use top-p sampling to generate 5 texts of maximum length 50 using your GPT-2 `generator`.  Set p equal to  0.1, 0.5, and 0.9 (a `for` loop might be useful here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. (4 points) P Effect\n",
    "\n",
    "Describe the qualitative difference in the generated text as `p` increases.  Discuss both the variety of the text and the coherence of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2. (28 points) Fine-Tuning on Tweets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. (4 points) Load Fine-Tuned GPT-2 Model\n",
    "\n",
    "Set `screen_name = \"KimKardashian\"`. Load the fine-tuned GPT-2 transformer for this user with the `pipeline` function and configure it for `\"text-generation\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. (10 points) Generate Fake Tweets with Top-P Sampling with Temperature\n",
    "\n",
    "Set `input_text = \"Today is going to be\"` and use top-p sampling to generate 5 texts of maximum length 50 using your fine-tuned GPT-2 `generator`.  Set `p=0.9` and `temperature = 0.8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. (10 points) Generate Fake Tweets with Top-P Sampling with Higher Temperature\n",
    "\n",
    "Set `input_text = \"Today is going to be\"` and use top-p sampling to generate 5 texts of maximum length 50 using your fine-tuned GPT-2 `generator`.  Set `p=0.9` and `temperature = 1.8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4 points) Comparing Temperatures\n",
    "\n",
    "Which fake tweets (high temperature or low temperature) sound more realistic to you?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. (16 points) Language Model Probability Distribution\n",
    "\n",
    "In this problem we will compare GPT-2 with the fine-tuned GPT-2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. (6 points) Sample Words from GPT-2\n",
    "\n",
    "Set `input_text = \"Hi my name is Kim\"`.  Generate 100 samples of the next word in this text using GPT-2.  Use the `sample_words` function from class (copy and paste works here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. (4 points) Sample Words from Fine-Tuned GPT-2\n",
    "\n",
    "Set `input_text = \"Hi my name is Kim\"`.  Generate 100 samples of the next word in this text using the fine-tuned GPT-2.  Use the `sample_words` function from class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. (4 points) Histograms of Word Distributions for GPT-2 and Fined Tuned GPT-2\n",
    "\n",
    "Make a histogram of the top 10 most frequent sampled words for GPT-2 and fine tuned GPT-2.  Label axes nicely.  Also, make sure to title the fine-tuned GPT-2 histogram with the screen name of user whose tweets were used to fine-tune it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (2 points) Fine-Tuning Effect\n",
    "\n",
    "Describe some of the differences among the most common words between GPT-2 and fine-tuned GPT-2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
